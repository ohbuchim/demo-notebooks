{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類ハンズオン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "本ノートブックでは，画像分類のビルトインアルゴリズムを使用して以下のことを行います。\n",
    "- CIFAR10のデータセットを使ってモデルを転移学習する\n",
    "- 転移学習したモデルでバッチ推論，リアルタイム推論する\n",
    "- ハイパーパラメタをチューニングする\n",
    "- チューニングしたモデルを使ってリアルタイム推論する\n",
    "\n",
    "### 画像分類モデルの転移学習\n",
    "本ノートブックでは，CIFAR10のデータセットを使って転移学習を行います。CIFAR10は，airplane（飛行機），automobile（自動車），bird（鳥），cat（猫），deer（鹿），dog（犬），frog（カエル），horse（馬），ship（船），truck（トラック）のいずれかが写っている 32x32画素の写真を集めてラベルをつけたデータセットです。 各クラスには6000 枚の画像が用意されており，学習用画像が全部で 50000 枚，テスト用画像が全部で 10000 枚あります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下準備\n",
    "\n",
    "### 権限や環境変数の設定\n",
    "\n",
    "下準備として，以下の処理を行います。\n",
    "\n",
    "* ロールの取得\n",
    "* モデルなどのデータを格納するS3バケット名\n",
    "* 画像分類のdockerコンテナを取得\n",
    "* データセットのダウンロードと画像への変換\n",
    "* lstファイルの作成\n",
    "* 画像とlstファイルをS3にアップロード\n",
    "\n",
    "**以下のセルの< BUCKET NAME >の部分を画像が格納されているS3バケット名に書き換えてください。**\n",
    "\n",
    "**以下のセルの< USER NAME >の部分をご自分の名前など，同じアカウントを使用する他の方と区別しやすいものに書き換えてください。**\n",
    "\n",
    "**以下のセルでは，学習と推論にml.p3.2xlargeを使用するよう設定していますが，ご自身のアカウントの状況によってはこのインスタンスを使用できないことがあります。その場合はご自身のアカウントの状況に合わせて最後の2行を書き換えてください。ただし，画像を使った学習を行うため，学習においてはp2やp3インスタンスを使用することが望ましいです。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = '< BUCKET NAME >'\n",
    "username = '< USER NAME >'\n",
    "\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "\n",
    "job_name_prefix = 'sagemaker-' + username\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "\n",
    "train_instance_type = 'ml.p2.xlarge'\n",
    "pred_instance_type = 'ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ取得\n",
    "CIFAR10のデータセットを https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz からダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar zvxf cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードした tar.gz ファイルからデータセットの画像を取り出します。\n",
    "\n",
    "CIFAR10 のデータセットには10クラス，60000枚の学習用画像がありますが，今回はデータセットから鳥，猫，犬の画像のみを使用します。学習用に各クラス500枚ずつ，検証用に各クラス50枚ずつの画像を使用します。\n",
    "\n",
    "## データ前処理\n",
    "取得したデータをモデルの入力形式に合わせるための前処理を行います。\n",
    "\n",
    "画像分類のビルトインアルゴリズムは以下の入力形式に対応しています。今回はイメージ形式を使用するため、lstファイルを作成します。\n",
    "* イメージ形式（lstファイルと画像）\n",
    "* RecordIO形式\n",
    "* 拡張マニフェスト形式（Amazon SageMaker Ground Truthの出力形式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train\n",
    "!mkdir validate\n",
    "!mkdir train/bird\n",
    "!mkdir train/cat\n",
    "!mkdir train/dog\n",
    "!mkdir validate/bird\n",
    "!mkdir validate/cat\n",
    "!mkdir validate/dog\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "train_data_list = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "val_data_list = ['test_batch']\n",
    "\n",
    "def save_as_jpg(mode, file_list, limit):\n",
    "    bird_counter = 0\n",
    "    cat_counter = 0\n",
    "    dog_counter = 0\n",
    "    limit_counter = 0\n",
    "    \n",
    "    for filepath in file_list:\n",
    "        res = unpickle('cifar-10-batches-py/' + filepath)\n",
    "        for idx, lb in enumerate(res[b'labels']):\n",
    "            d = res[b'data'][idx].reshape([3, 32, 32])\n",
    "            d = d.transpose(1, 2, 0)\n",
    "            img = Image.fromarray(d)\n",
    "            if lb == 2:\n",
    "                if bird_counter > limit:\n",
    "                    limit_counter += 1\n",
    "                    continue\n",
    "                img.save(mode + '/bird/bird_' + str(bird_counter).zfill(6) + '.jpg')\n",
    "                bird_counter += 1\n",
    "            elif lb == 3:\n",
    "                if cat_counter > limit:\n",
    "                    limit_counter += 1\n",
    "                    continue\n",
    "                img.save(mode + '/cat/cat_' + str(cat_counter).zfill(6) + '.jpg')\n",
    "                cat_counter += 1\n",
    "            elif lb == 5:\n",
    "                if dog_counter > limit:\n",
    "                    limit_counter += 1\n",
    "                    continue\n",
    "                img.save(mode + '/dog/dog_' + str(dog_counter).zfill(6) + '.jpg')\n",
    "                dog_counter += 1\n",
    "            if limit_counter == 3:\n",
    "                break\n",
    "\n",
    "save_as_jpg('train', train_data_list, 500)\n",
    "save_as_jpg('validate', val_data_list, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im2rec.pyをダウンロードし，これを使って学習用，検証用のlstファイルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py -O im2rec.py\n",
    "python im2rec.py --list --recursive cifar_train train/\n",
    "python im2rec.py --list --recursive cifar_validate validate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ローカルにある画像とlstファイルを SageMaker が使える状態にするために，S3 にアップロードします。<br>\n",
    "まずはS3とローカルのパスを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3train = 's3://{}/{}/train/'.format(bucket, username)\n",
    "s3validation = 's3://{}/{}/validation/'.format(bucket, username)\n",
    "s3train_lst = 's3://{}/{}/train_lst/'.format(bucket, username)\n",
    "s3validation_lst = 's3://{}/{}/val_lst/'.format(bucket, username)\n",
    "val_lst_name = 'cifar_validate.lst'\n",
    "train_lst_name = 'cifar_train.lst'\n",
    "s3_train_lst_path = 's3://{}/{}/train_lst/{}'.format(bucket, username, train_lst_name)\n",
    "s3_validation_lst_path = 's3://{}/{}/val_lst/{}'.format(bucket, username, val_lst_name)\n",
    "\n",
    "local_validation_data_path = './validate/'\n",
    "local_train_data_path = './train/'\n",
    "object_categories = ['bird', 'cat', 'dog'] # 分類するクラスのラベル\n",
    "batch_output_dir = 'cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awsコマンドで画像とlstファイルをS3にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $local_train_data_path $s3train --recursive --quiet\n",
    "!aws s3 cp $train_lst_name $s3_train_lst_path --quiet\n",
    "\n",
    "!aws s3 cp $local_validation_data_path $s3validation --recursive --quiet\n",
    "!aws s3 cp $val_lst_name $s3_validation_lst_path --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "のちほどモデルの精度を確認する際に使用するために，以下のセルを実行してvalidation用lstファイルを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "act_label = pd.read_csv(val_lst_name, header=None, sep='\\t', names=['index', 'label', 'file'])\n",
    "print(act_label[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを学習させる前に，学習パラメタを設定する必要があります。次のセクションではパラメタの詳細を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "データの準備ができたら、学習を行います。\n",
    "\n",
    "### 学習パラメタの設定\n",
    "以下に説明するようなアルゴリズム特有のハイパーパラメタを設定します。\n",
    "\n",
    "* **num_layers**: ネットワークの層の数です。18, 34, 50, 101, 152,  200を使用できます。\n",
    "* **image_shape**: 入力画像の次元を示し，'num_channels, height, width'の順で設定します。実際のサイズよりも大きい値を設定することはできません。チャネルの数は実際の画像と同じものにしてください。\n",
    "* **num_training_samples**: 学習サンプルの総数です。caltechデータセットの場合は15240を指定します。今回は500枚＊3クラスで1500を設定します。\n",
    "* **num_classes**: 新しいデータセットの分類クラス数です。Imagenetは1000のクラスに分類されますが，出力されるクラス数は転移学習の際に変えることができます。caltechデータセットの場合，クラス数はオブジェクトカテゴリ256種類＋カテゴリ外1で257を設定します。今回は鳥，猫，犬の3パターンを分類するので3を設定します。\n",
    "* **mini_batch_size**: 各ミニバッチで使用する学習サンプルの数です。分散学習の場合，バッチごとに使用される学習サンプルの数はN＊mini_batchi_sizeとなります。Nは学習が実行されるホストの数です。\n",
    "* **epochs**: 学習エポックの数です。\n",
    "* **learning_rate**: 学習率です。\n",
    "* **top_k**: 学習中のトップkの精度をリポートします。\n",
    "* **resize**: 学習前に画像をリサイズします。画像は短辺がこの値になるようリサイズされます。値がセットされていない場合は，学習データはリサイズなしで使用されます。\n",
    "* **checkpoint_frequency**: モデルパラメタを保存する頻度をエポック数で指定します。\n",
    "* **use_pretrained_model**: 転移学習をする場合は1を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "num_layers = 18\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = \"3,32,32\"\n",
    "# we also need to specify the number of training samples in the training set\n",
    "num_training_samples = 1500\n",
    "# specify the number of output classes\n",
    "num_classes = 3\n",
    "# batch size for training\n",
    "mini_batch_size = 20\n",
    "# number of epochs\n",
    "epochs = 20\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "# report top_k accuracy\n",
    "top_k = 2\n",
    "# period to store model parameters (in number of epochs), in this case, we will save parameters from epoch 2, 4, and 6\n",
    "checkpoint_frequency = 2\n",
    "# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be \n",
    "# initialized with pre-trained weights\n",
    "use_pretrained_model = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker関連の学習パラメタの設定\n",
    "それでは，学習を始めましょう。<br>\n",
    "まずは学習インスタンスを立てるために必要なパラメタを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, username)\n",
    "estimator = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                          train_instance_type=train_instance_type, \n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         base_job_name = job_name_prefix,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習アルゴリズム関連の学習パラメタの設定\n",
    "次に，モデルのハイパーパラメタを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(num_layers=num_layers, # レイヤー数\n",
    "                             image_shape = image_shape,# 画像サイズ\n",
    "                             num_classes=num_classes, # クラス数\n",
    "                             num_training_samples=num_training_samples, # 学習データ数\n",
    "                             mini_batch_size=mini_batch_size, # ミニバッチ(一度に学習させる単位)の画像枚数\n",
    "                             epochs=epochs, # エポック数(同じデータを何回学習させるか)\n",
    "                             learning_rate=learning_rate, # 学習率\n",
    "                             top_k=top_k, # レポートされる精度の計算方法（上位何個のラベルのなかに答えのラベルがあれば正解とするか)\n",
    "                             use_pretrained_model = use_pretrained_model,\n",
    "                             precision_dtype='float32' # 計算時の精度。精度を落とすことで計算量が減る\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力データ形式の設定\n",
    "次に，学習データと検証データを使用する準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "train_lst = sagemaker.session.s3_input(s3train_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3validation, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_lst = sagemaker.session.s3_input(s3validation_lst, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    " \n",
    "data_channels = {'train': train_data, 'validation': validation_data, 'train_lst': train_lst, 'validation_lst': validation_lst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習ジョブ起動（学習開始）\n",
    "\n",
    "fit関数で学習を実行します。<br><br>\n",
    "ログに Completed - Training job completed と表示されたら学習の完了です。<br>\n",
    "学習ジョブは以下のURLから参照可能です。<br>\n",
    "注）以下のURLはバージニア北部リージョンのものです。他のリージョンをご利用の場合はリンクをクリック後にブラウザでリージョンを変更してください。<br>\n",
    "https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "モデルの学習が終わったら、学習済みモデルを使って推論を行います。<br>\n",
    "SageMakerではバッチ推論とリアルタイム推論の２通りの推論方法の利用が可能です。\n",
    "### バッチ推論\n",
    "まずは推論を実行するたびに推論インスタンスを立てるバッチ推論を試してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform関数でバッチ推論を実行します。<br>\n",
    "バッチ推論が完了するまで数分かかります。<br>\n",
    ".が表示されたのち最後に！が出てきたらバッチ推論は完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output_s3_dir = 's3://{}/{}/batch-inference/output/{}'\n",
    "batch_output = batch_output_s3_dir.format(bucket, username, batch_output_dir)\n",
    "transformer = estimator.transformer(instance_count=1, instance_type=pred_instance_type, output_path=batch_output)\n",
    "transformer.transform(data=s3validation, data_type='S3Prefix', content_type='application/x-image')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ推論結果は上のセルでtransformer関数を呼び出す際の `output_path` で指定された場所に保存されます。<br>\n",
    "ここでは，S3に保存された推論結果ファイルを読み込み，推論結果を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "def list_objects(s3_client, bucket, prefix):\n",
    "    response = s3_client.list_objects(Bucket=bucket, Prefix=prefix)\n",
    "    objects = [content['Key'] for content in response['Contents']]\n",
    "    return objects\n",
    "\n",
    "counter = 0\n",
    "def get_label(s3_client, bucket, prefix):\n",
    "    filename = prefix.split('/')[-1]\n",
    "    s3_client.download_file(bucket, prefix, filename)\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        index = np.argmax(data['prediction'])\n",
    "        probability = data['prediction'][index]\n",
    "    \n",
    "    global counter\n",
    "    fname = os.path.basename(filename)[:-4]\n",
    "    label = act_label[act_label['file'].str.contains(fname)]['label'].values[0]\n",
    "    okng = 'NG'\n",
    "    if label == index:\n",
    "        okng = 'OK'\n",
    "        counter += 1\n",
    "    print(\"Result: \" + okng + \", file - \" + filename + \", label - \" + object_categories[int(label)] + \", pred - \" + object_categories[index] + \", probability - \" + str(round(probability, 2)))\n",
    "    return object_categories[index], probability\n",
    "\n",
    "outputs = list_objects(s3_client, bucket, username + \"/batch-inference/output/\"+ batch_output_dir)\n",
    "\n",
    "\n",
    "[get_label(s3_client, bucket, prefix) for prefix in random.sample(outputs, 20)]\n",
    "print('accuracy - ' + str(round(counter/20, 2)))\n",
    "!rm *.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### リアルタイム推論\n",
    "次に，リアルタイム推論を行います。<br>\n",
    "まずはdeploy関数で推論エンドポイントを立てます。<br>\n",
    "エンドポイントが立ち上がるまで数分かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=pred_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict関数で推論エンドポイントにひとつずつデータを送って推論を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "validation_image_list = sorted(glob.glob(os.path.join(local_validation_data_path, '**/*.jpg'), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def predict_images(predictor):\n",
    "    counter = 0\n",
    "    for file_name in random.sample(validation_image_list, 20):\n",
    "\n",
    "        with open(file_name, 'rb') as f:\n",
    "            payload = f.read()\n",
    "            payload = bytearray(payload)\n",
    "            \n",
    "        response = predictor.predict(payload).decode()\n",
    "        \n",
    "        res_list = list(map(float, response[1:-1].split(',')))\n",
    "        index = np.argmax(res_list)\n",
    "        prob = max(res_list)\n",
    "\n",
    "        fname = os.path.basename(file_name)\n",
    "        label = act_label[act_label['file'].str.contains(fname)]['label'].values[0]\n",
    "        okng = 'NG'\n",
    "        if label == index:\n",
    "            okng = 'OK'\n",
    "            counter += 1\n",
    "        print(\"Result: \" + okng + \", image name - \" + fname + \", label - \" + object_categories[int(label)] + \n",
    "              \", pred - \" + object_categories[index] + \", probability - \" + str(round(prob, 2)) )\n",
    "    print('accuracy - ' + str(round(counter/20, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_images(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論エンドポイントは起動している間課金対象となりますので，不要になったらすぐに削除することが推奨されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すでに学習済みのモデルがある場合，モデルが保存されているS3の場所を指定して以下のように推論エンドポイントを立てることが可能です。<br>\n",
    "詳細は[自分で事前にトレーニングした MXNet または TensorFlow のモデルを Amazon SageMaker に導入する](https://aws.amazon.com/jp/blogs/news/bring-your-own-pre-trained-mxnet-or-tensorflow-models-into-amazon-sagemaker/)をご参照ください。\n",
    "\n",
    "```python\n",
    "sagemaker_model = MXNetModel(model_data = 's3://xxxx/model/model.tar.gz',\n",
    "                             role = role,\n",
    "                             entry_point = 'classifier.py')\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメタチューニング\n",
    "ハイパーパラメータの値が適切でない場合，学習が収束しなかったり期待する精度にならなかったりすることがあります。<br>\n",
    "ここからは，SageMakerによるハイパーパラメタチューニングの手順を学びます。\n",
    "\n",
    "まず，ハイパーパラメタを探索する範囲を各ハイパーパラメタに対して設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'adam']),\n",
    "                         'mini_batch_size': IntegerParameter(10, 64),\n",
    "                         'learning_rate': ContinuousParameter(1e-4, 0.5),\n",
    "                         'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'nag']),\n",
    "                        'momentum': ContinuousParameter(0, 0.999),\n",
    "                        'weight_decay': ContinuousParameter(0, 0.999),\n",
    "                        'beta_1': ContinuousParameter(1e-4, 0.999),\n",
    "                        'beta_2': ContinuousParameter(1e-4, 0.999),\n",
    "                        'eps': ContinuousParameter(1e-4, 1.0),\n",
    "                        'gamma': ContinuousParameter(1e-4, 0.999)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，使用するメトリクスを設定します。ここでは，検証データの精度を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "metric_definitions = [{'Name': 'Validation-accuracy',\n",
    "                       'Regex': 'Validation-accuracy=([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，上で設定した値を使ってハイパーパラメタチューニングジョブの設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            base_tuning_job_name = job_name_prefix,\n",
    "                            max_jobs=4,\n",
    "                            max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit関数でハイパーパラメタチューニングジョブを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': train_data, 'validation': validation_data, 'train_lst': train_lst, 'validation_lst': validation_lst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のセルを実行すると，実行中であることを示すアスタリスクがすぐに数字になり実行が完了したかのように見えますが，実際はハイパーパラメタチューニングジョブが走っています。\n",
    "以下のセルを実行して，ハイパーパラメタチューニングジョブのステータスを表示してみましょう。<br>\n",
    "ステータスが InProgress から Completed になったらハイパーパラメタのチューニングが完了です。\n",
    "\n",
    "ハイパーパラメタチューニングのステータスはこちらのURLから確認することも可能です。<br>\n",
    "以下はバージニア北部のリージョンのURLです。他のリージョンを使用している場合は，以下のURLをクリックしたのちマネジメントコンソール右上のプルダウンメニューから適切なリージョンを選択してください。<br>\n",
    "https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チューニングしたモデルを使って推論用のエンドポイントを立てます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=pred_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リアルタイム推論のときに作成した `predict_images` を使用して，validation用画像で推論して結果を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_images(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントの削除\n",
    "忘れずにエンドポイントを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
