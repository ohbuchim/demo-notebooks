{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ビルトインアルゴリズムと拡張マニフェストファイルを使った画像分類\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# はじめに\n",
    "***\n",
    "\n",
    "このノートブックは、Amazon SageMaker Ground Truth でラベリングした結果を使って画像分類モデルを作成するためのノートブックです。 [こちらの記事](https://aws.amazon.com/jp/builders-flash/202005/sagemaker-groundtruth-cat/) に対応しています。このノートブックを使用する前に、Amazon SageMaker Ground Truth を使って画像のラベリングが完了している必要があります。\n",
    "\n",
    "Amazon SageMaker Ground Truth を使った画像のラベリング方法については [こちらの記事](https://aws.amazon.com/jp/builders-flash/202003/sagemaker-groundtruth-cat/) をご参照ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期設定\n",
    "***\n",
    "\n",
    "## 環境設定\n",
    "\n",
    "まずはじめに、**みなさまの環境に合わせて以下の変数の値を変更します。**各変数に設定すべき値は以下の手順で確認可能です。\n",
    "\n",
    "1. **labeling_job_name**<br>\n",
    "Amazon SageMaker コンソールの左側のメニューの [ラベリングジョブ] をクリックし、ラベリングジョブ一覧を表示させます。ここの [名前] 欄にあるのがラベリングジョブ名です。該当のラベリングジョブ名をコピーしてこちらに設定します。\n",
    "1. **your_augmented_manifest_file**<br>\n",
    "上記手順で表示したラベリングジョブ一覧の中から使用したいラベリングジョブをクリックします。[ラベリングジョブの概要] 部分に [出力データセットの場所] というリンクがあるのでそちらをクリックします。そこから manifests -> output とフォルダをたどると output.manifest があります。そちらをクリックし、[コピーパス] というボタンをクリックすると、output.manifest ファイルの S3 パスがコピーされるので、それをペーストします。\n",
    "1. **object_categories**<br>\n",
    "上記手順で　[出力データセットの場所] というリンクをクリック後、annotation-tool フォルダをクリックすると、data.json というファイルがあります。こちらをクリックし [ダウンロード] ボタンをクリックしてダウンロードします。テキストエディタなどでこのファイルを開くと、ラベリング時に使用したラベルの名前と順番がわかりますので、こちらを参考に設定します。\n",
    "1. **width, height**<br>\n",
    "上記手順1 で表示したラベリングジョブ一覧の中から使用したいラベリングジョブをクリックします。[ラベル付きデータセットオブジェクト] 部分に画像が表示されるので、そちらをクリックするとその画像が保存されている S3 パスがわかります。こちらから画像をダウンロードして、画像のサイズを確認できます。\n",
    "\n",
    "変数の設定が完了したら、セルを選択した状態で Shift + Enter を実行するか、上にある Run ボタンをクリックするとセルが実行されます。セルというのは、ソースコードが書かれたテキスト領域のことです。セルを実行すると、セルの左側にある In [ ]: のカッコの中に数字が表示されます。セルの処理が実行中の場合は数字ではなく * が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon SageMaker Ground Truth のラベリングジョブ名\n",
    "labeling_job_name = 'cats'\n",
    "\n",
    "# Amazon SageMaker Ground Truth のラベリング結果の output.manifest の S3パス\n",
    "your_augmented_manifest_file = 's3://cat-image-classification/output/cats/manifests/output/output.manifest'\n",
    "\n",
    "# Amazon SageMaker Ground Truth で使用したラベルの名前。ラベリング時と順番を揃える必要があります。\n",
    "object_categories = ['mike', 'tama']\n",
    "\n",
    "\n",
    "# 学習に使用する画像（Amazon SageMaker Ground Truth でラベリングした画像）のサイズ\n",
    "width = 2000\n",
    "height = 1333\n",
    "channel = 3 # 基本的にここは変更する必要はありません。カラー画像であればたいてい RGB の 3チャネルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker を使うための設定\n",
    "\n",
    "ここでは、AWS のサービスを使う上で必要な設定を行います。こちらは変更の必要はありません。どんどんセルを実行していきましょう。\n",
    "\n",
    "* このノートブックインスタンスで使用しているロールの情報の取得\n",
    "* デフォルト S3 バケット名の取得。こちらに学習したモデルなどを保存します\n",
    "* The Amazon SageMaker の画像分類アルゴリズムの docker イメージパスの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'ic-transfer-learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの準備\n",
    "***\n",
    "\n",
    "ここでは、Amazon SageMaker Ground Truth でラベリングした結果を、学習用と検証用に分けて S3 にアップロードします。こちらは変更の必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# S3 から output.manifest をダウンロード\n",
    "tmp_manifest = '/tmp/output.manifest'\n",
    "! aws s3 cp {your_augmented_manifest_file} {tmp_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.manifest を学習用と検証用に分割\n",
    "\n",
    "import random\n",
    "\n",
    "with open(tmp_manifest) as f:\n",
    "    data = [l.rstrip() for l in f.readlines()]\n",
    "    \n",
    "line_count = len(data)\n",
    "num_training_samples = int(line_count * 0.7)\n",
    "\n",
    "index = list(range(0, line_count))\n",
    "random.shuffle(index)\n",
    "\n",
    "train_data  = data[:num_training_samples]\n",
    "valid_data = data[num_training_samples:]\n",
    "\n",
    "train_manifest = '/tmp/train.manifest'\n",
    "valid_manifest = '/tmp/valid.manifest'\n",
    "with open(train_manifest, 'w') as f:\n",
    "    for d in train_data:\n",
    "        f.write(\"%s\\n\" % d)\n",
    "with open(valid_manifest, 'w') as f:\n",
    "    for d in valid_data:\n",
    "        f.write(\"%s\\n\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用と検証用の manifest ファイルを S3 にアップロード\n",
    "\n",
    "import os\n",
    "s3path = os.path.dirname(your_augmented_manifest_file)\n",
    "train_manifest_s3 = s3path + '/train.manifest'\n",
    "valid_manifest_s3 = s3path + '/valid.manifest'\n",
    "! aws s3 cp {train_manifest} {train_manifest_s3}\n",
    "! aws s3 cp {valid_manifest} {valid_manifest_s3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類モデルの学習\n",
    "***\n",
    "\n",
    "ここまでで、必要な準備が完了しました。ここでは、画像分類モデルを作ります。始めに ``sageMaker.estimator.Estimator`` オブジェクトを作ります。この estimator から学習ジョブを立ち上げます。こちらも特に変更が必要な部分はありません。\n",
    "\n",
    "## 学習パラメータ\n",
    "\n",
    "モデルを学習するにあたって、2種類のパラメータを設定する必要があります。1つは学習ジョブの設定、もう1つは画像分類モデルのハイパーパラメータです。\n",
    "\n",
    "学習ジョブの設定には以下のようなものがあります。\n",
    "\n",
    "* **学習インスタンスの数**: 学習ジョブで使用するインスタンスの数です。1よりも大きな値を設定することで分散学習を実行することができます。ただし、画像分類のビルトインアルゴリズムは Pipe モード時の分散学習に対応していません。本ノートブックのように Amazon SageMaker Ground Truth が出力した拡張マニフェストファイルを使用する場合はファイル転送を Pipe モードにする必要があるため、分散学習を使用することはできませんのでご注意ください。\n",
    "* **学習インスタンスタイプ**: 学習ジョブで使用するインスタンスタイプです。一般的に画像分類モデルを学習させる際は GPU を搭載したインスタンスを使用します。\n",
    "* **出力パス**: 学習ジョブの出力を保存する場所を示す S3 パスです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ジョブの設定\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                      role,\n",
    "                                      train_instance_count=1,\n",
    "                                      train_instance_type='ml.p2.xlarge',\n",
    "                                      train_volume_size = 50,\n",
    "                                      train_max_run = 360000,\n",
    "                                      input_mode = 'Pipe',\n",
    "                                      output_path=s3_output_location,\n",
    "                                      sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像分類モデルのハイパーパラメータには以下のようなものがあります。\n",
    "\n",
    "* **num_layers**: モデルネットワークの層の数です。このサンプルでは 18 を使用しますが、他に 50, 152 を選択できます。\n",
    "* **use_pretrained_model**: 1 を設定することで学習済みモデルを使って転移学習をすることができます。\n",
    "* **image_shape**: 学習に使用する画像のサイズです。チャネル数、高さ、幅、の順で設定します。実際の画像サイズより大きな値を設定しないようにしてください。\n",
    "* **num_classes**: 画像分類の分類ラベルの数です。Imagenet は 1000 クラスの分類ですが、実際に使用したいラベルの数に合わせてクラスの数を変更します。2 匹の猫を分類するモデルを作る場合は、2 を設定します。\n",
    "* **num_training_samples**: 学習に用いる画像の枚数を設定します。\n",
    "* **mini_batch_size**: 各ミニバッチで使用する学習サンプル数です。分散学習では、バッチごとに使用される学習サンプル数は N * mini_batch_size となり、Nは訓練を実行するホストの数を意味します。\n",
    "* **epochs**: 学習エポック数です。\n",
    "* **learning_rate**: 学習率です。\n",
    "* **precision_dtype**: 学習データの精度 (default: float32) です。float16 に設定した場合、学習は mixed_precision モードとなり、float32 よりも高速に学習します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像分類モデルのハイパーパラメータの設定\n",
    "\n",
    "ic.set_hyperparameters(num_layers=18,\n",
    "                             use_pretrained_model=1,\n",
    "                             image_shape = str(channel)+','+str(height)+','+str(width),\n",
    "                             num_classes=len(object_categories),\n",
    "                             num_training_samples=num_training_samples,\n",
    "                             mini_batch_size=4,\n",
    "                             epochs=20,\n",
    "                             learning_rate=0.01,\n",
    "                             precision_dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データの設定\n",
    "\n",
    "学習データの形式を定義します。今回は Amazon SageMaker Ground Truth で作成した拡張マニフェスト形式のファイルを使用するための設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拡張マニフェスト形式のファイルを学習データとして使用するよう設定\n",
    "\n",
    "train_data = sagemaker.session.s3_input(train_manifest_s3,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', labeling_job_name]) \n",
    "validation_data = sagemaker.session.s3_input(valid_manifest_s3,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', labeling_job_name]) \n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の開始\n",
    "\n",
    "定義した estimator の fit() を実行して学習ジョブを開始します。ログの最後には、\n",
    "\n",
    "```\n",
    "Training seconds: 255\n",
    "Billable seconds: 255\n",
    "```\n",
    "のように、学習ジョブに対して課金される対象となる時間が秒単位で表示されます。\n",
    "\n",
    "\n",
    "> **注意： ResourceLimitExceeded というエラーが出たら**<br>\n",
    "作ったばかりの新しい AWSアカウントを使用する場合など、ノートブック実行中に ResourceLimitExceeded というエラーが出ることがあります。その場合は [サポートセンター](https://console.aws.amazon.com/support/home#/) から 「ケースの作成」 をクリックしたのち 「サービス制限の緩和」を選択し、以下の設定でケースを作成します。\n",
    "> - 制限タイプ：SageMaker\n",
    "> - リージョン：米国東部（バージニア北部）　※実際に使用するリージョンを選択してください\n",
    "> - リソースタイプ：学習実行時にエラーが出た場合は「SageMaker のトレーニング」、推論時にエラーが出た場合は「SageMaker のホスト」\n",
    "> - 制限：使用するインスタンスタイプ\n",
    "> - 申請理由の説明：ハンズオンで使用するため、など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論\n",
    "\n",
    "***\n",
    "\n",
    "## 推論環境の起動\n",
    "モデルを学習しただけでは何も起こりません。作ったモデルを使って、推論してみましょう。estimator の deploy() を実行して推論環境を立ち上げます。ログにはしばらく `-` が表示され、処理が完了したら `!` が表示されます。こちらの処理が完了するまでは 5分から 10分程度かかります。\n",
    "\n",
    "ResourceLimitExceeded というエラーが出たら、[学習の開始](#学習の開始) に記載の手順でサービス制限の緩和を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = ic.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論用画像の準備\n",
    "\n",
    "S3 に保存してある画像をダウンロードして、推論してみます。画像は `/tmp` にダウンロードされます。**S3 のパスは、みなさまの環境に合わせて書き換えてください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を S3 からローカル（ノートブックインスタンス）の /tmp/にダウンロード\n",
    "\n",
    "!aws s3 cp \"s3://cat-image-classification/cats/DSC_0022.jpg\" /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードした画像を確認します。**`file_name` は先ほどダウンロードした画像の名前に書き換えてください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 画像の表示\n",
    "\n",
    "file_name = '/tmp/DSC_0022.jpg'\n",
    "from IPython.display import Image\n",
    "Image(file_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論の実行\n",
    "\n",
    "立ち上げた推論環境に写真を送って、推論します。推論結果としては、各ラベルと、そのラベルである確率（probability）が出力されます。そこから、最も probability が高いものを最終結果とします。\n",
    "\n",
    "**注意:** 結果がいまひとつの場合、学習に使用する画像を増やす、ハイパーパラメータの epoch の数を増やす、その他のハイパーパラメータチューニングを行うなどで精度の向上が見込めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロードした写真を読み込んで、推論環境に送り推論結果を取得し、最終結果を表示\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "ic_classifier.content_type = 'application/x-image'\n",
    "result = json.loads(ic_classifier.predict(payload))\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n",
    "index = np.argmax(result)\n",
    "\n",
    "print(\"写っているのは \" + object_categories[index] + \"です！ （probability - \" + str(round(result[index]*100, 1)) + '%）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リソースの削除\n",
    "***\n",
    "不要な課金を防ぐため、使用しないリソースは削除しましょう。なお、削除したデータは戻せないのでご注意ください。本ノートブックを実行することで使用される AWS サービスは以下の通りです。削除方法は [こちら](https://aws.amazon.com/jp/builders-flash/202005/sagemaker-groundtruth-cat/) の記事の「リソースの削除」の章をご参照ください。\n",
    "- Amazon S3 バケット\n",
    "- Amazon SageMaker ノートブックインスタンス\n",
    "- Amazon SageMaker エンドポイント\n",
    "\n",
    "## 推論環境（エンドポイント）の削除\n",
    "\n",
    "推論環境は立ち上げている間課金されるので、推論したい画像がなくなったら次のコマンドを実行して推論環境を削除しましょう。\n",
    "\n",
    "Amazon SageMaker のコンソールからエンドポイント一覧の画面に行き、そちらからエンドポイントを削除することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
