{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 類似画像検索\n",
    "\n",
    "## パスの設定\n",
    "`image_path_s3` に、検索対象となる画像が格納されている S3 のパスを記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_s3 = 's3://bucket/directory/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行環境の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install hnswlib\n",
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import multiprocessing\n",
    "from mxnet.gluon.data.vision.datasets import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "import numpy as np\n",
    "# import wget\n",
    "import imghdr\n",
    "import json\n",
    "import pickle\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "import glob, os, time\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "import urllib.parse\n",
    "import urllib\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "import glob\n",
    "from os.path import join\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習モデルの設定\n",
    "このサンプルでは、画像から特徴ベクトルに変換するために学習済みの機械学習モデルを使用します。<br>\n",
    "ここでは、MXNet の model-zoo のモデルを使用します。model-zoo のネットワークは、特徴量が .features プロパティにあり、出力が .output プロパティにあります。この仕組みを利用して、事前にトレーニングされたネットワークを使って featurizer を非常に簡単に作成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EMBEDDING_SIZE = 512\n",
    "SIZE = (224, 224)\n",
    "MEAN_IMAGE= mx.nd.array([0.485, 0.456, 0.406])\n",
    "STD_IMAGE = mx.nd.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if len(mx.test_utils.list_gpus()) else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vision.resnet18_v2(pretrained=True, ctx=ctx).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    resized = mx.image.resize_short(image, SIZE[0]).astype('float32')\n",
    "    cropped, crop_info = mx.image.center_crop(resized, SIZE)\n",
    "    cropped /= 255.\n",
    "    normalized = mx.image.color_normalize(cropped,\n",
    "                                      mean=MEAN_IMAGE,\n",
    "                                      std=STD_IMAGE) \n",
    "    transposed = nd.transpose(normalized, (2,0,1))\n",
    "    return transposed, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "S3 から画像をダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folder = tempfile.mkdtemp()\n",
    "# Create an empty image Folder Data Set\n",
    "dataset = ImageFolderDataset(root=empty_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp $image_path_s3 $image_path --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(os.path.join(image_path, '**.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[{}] images\".format(len(list_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.items = list(zip(list_files, [0]*len(list_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, last_batch='keep', shuffle=False, num_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像から特徴ベクトルに変換\n",
    "機械学習モデルを使って画像を特徴ベクトルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros((len(dataset), EMBEDDING_SIZE), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tick = time.time()\n",
    "n_print = 100\n",
    "j = 0\n",
    "for i, (data, label) in enumerate(dataloader):\n",
    "    data = data.as_in_context(ctx)\n",
    "    if i%n_print == 0 and i > 0:\n",
    "        print(\"{0} batches, {1} images, {2:.3f} img/sec\".format(i, i*BATCH_SIZE, BATCH_SIZE*n_print/(time.time()-tick)))\n",
    "        tick = time.time()\n",
    "    output = net(data)\n",
    "    features[(i)*BATCH_SIZE:(i+1)*max(BATCH_SIZE, len(output)), :] = output.asnumpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検索のための準備\n",
    "このサンプルでは、hnswlib を使って類似ベクトルを検索します。<br>\n",
    "ここでは、hnswlib のセットアップをします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of elements in the index\n",
    "num_elements = len(features)\n",
    "labels_index = np.arange(num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring index\n",
    "p = hnswlib.Index(space = 'cosine', dim = EMBEDDING_SIZE) # possible options are l2, cosine or ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Initing index - the maximum number of elements should be known beforehand\n",
    "p.init_index(max_elements = num_elements, ef_construction = 100, M = 16)\n",
    "\n",
    "# Element insertion (can be called several times):\n",
    "int_labels = p.add_items(features, labels_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[efパラメーター](https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md) で定義された、クエリ時間の精度と速度のトレードオフを設定します。\n",
    "ここでは、最近傍の動的リストのサイズを設定しています（検索中に使用されます）。 設定した値が大きいほど、検索はより正確ですが遅くなります。 この設定値は、クエリされた最近傍の数kより小さな値を設定することはできません。この設定値は、kとデータセットのサイズの間の任意の値を設定可能です。\n",
    "\n",
    "現在、パラメータはインデックスと一緒に保存されないため、ロード後に手動で設定する必要があることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlling the recall by setting ef:\n",
    "p.set_ef(300) # ef should always be > k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save_index(join('mms', 'index.idx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load_index(join('mms','index.idx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 類似画像の検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(images):\n",
    "    rows = len(images)//3+2\n",
    "    gs = gridspec.GridSpec(rows, 3)\n",
    "    fig = plt.figure(figsize=(15, 5*rows))\n",
    "    gs.update(hspace=0.1, wspace=0.1)\n",
    "    for i, (gg, image) in enumerate(zip(gs, images)):\n",
    "        gg2 = gridspec.GridSpecFromSubplotSpec(10, 10, subplot_spec=gg)\n",
    "        ax = fig.add_subplot(gg2[:,:])\n",
    "        ax.imshow(image, cmap='Greys_r')\n",
    "        ax.tick_params(axis='both',       \n",
    "                       which='both',      \n",
    "                       bottom='off',      \n",
    "                       top='off',         \n",
    "                       left='off',\n",
    "                       right='off',\n",
    "                       labelleft='off',\n",
    "                       labelbottom='off') \n",
    "        ax.axes.set_title(\"result [{}]\".format(i))\n",
    "        if i == 0:\n",
    "            plt.setp(ax.spines.values(), color='red')\n",
    "            ax.axes.set_title(\"SEARCH\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def search(N, k):\n",
    "    # Query dataset, k - number of closest elements (returns 2 numpy arrays)\n",
    "    start = time.time()\n",
    "    q_labels, q_distances = p.knn_query([features[N]], k = k+1)\n",
    "    time_for_query = (time.time()- start)*1000\n",
    "    print('time for query: ', str(time_for_query)+' msec')\n",
    "    images = [plt.imread(dataset.items[label][0]) for label in q_labels[0][1:]]\n",
    "    plot_predictions(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用意した画像の中からランダムに 1枚の画像を選び、その画像と類似する画像を検索して表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "index = np.random.randint(0,len(features))\n",
    "print(index)\n",
    "k = 6\n",
    "search(index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
